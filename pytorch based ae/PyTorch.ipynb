{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "import scipy.io as sio\n",
    "import torch.utils.data as Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(5, 64, kernel_size=17, padding=8)\n",
    "        init.xavier_uniform_(self.conv1.weight)\n",
    "        self.conv_bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc1 = nn.Linear(3520, 1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=17, padding=8)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=17, padding=8)\n",
    "        self.conv_bn2 = nn.BatchNorm1d(128)\n",
    "        self.conv4 = nn.Conv1d(128, 128, kernel_size=17, padding=8)\n",
    "        self.conv5 = nn.Conv1d(128, 192, kernel_size=17, padding=8)\n",
    "        self.conv_bn3 = nn.BatchNorm1d(192)\n",
    "        self.conv6 = nn.Conv1d(192, 192, kernel_size=17, padding=8)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        x = F.relu(self.conv_bn1(self.conv1(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.conv_bn1(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.max_pool1d(x, 2)\n",
    "        x = F.relu(self.conv_bn1(self.conv2(x)))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "#         x = F.relu(self.conv_bn2(self.conv3(x)))\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         x = self.conv4(x)\n",
    "#         x = F.max_pool1d(x, 2)\n",
    "#         x = F.relu(self.conv_bn2(x))\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         x = F.relu(self.conv_bn3(self.conv5(x)))\n",
    "#         x = self.dropout(x)\n",
    "        \n",
    "#         x = self.conv6(x)\n",
    "#         x = F.max_pool1d(x, 2)\n",
    "#         x = F.relu(self.conv_bn3(x))\n",
    "#         x = self.dropout(x)\n",
    "# #         print(x)\n",
    "        \n",
    "#         print(x.size())\n",
    "        x = x.view(-1, 3520)\n",
    "#         print(x.size())\n",
    "        x = self.fc1(x)\n",
    "#         print(x.size())\n",
    "        return F.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = Net().to(device)\n",
    "#model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 110]           5,504\n",
      "       BatchNorm1d-2              [-1, 64, 110]             128\n",
      "           Dropout-3              [-1, 64, 110]               0\n",
      "            Conv1d-4              [-1, 64, 110]          69,696\n",
      "       BatchNorm1d-5              [-1, 64, 110]             128\n",
      "           Dropout-6              [-1, 64, 110]               0\n",
      "            Conv1d-7               [-1, 64, 55]          69,696\n",
      "       BatchNorm1d-8               [-1, 64, 55]             128\n",
      "           Dropout-9               [-1, 64, 55]               0\n",
      "           Linear-10                    [-1, 1]           3,521\n",
      "================================================================\n",
      "Total params: 148,801\n",
      "Trainable params: 148,801\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xufanxiong/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "summary(model, (5, 110))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-6, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3055, 1)\n",
      "(3055, 5, 110)\n"
     ]
    }
   ],
   "source": [
    "dataset = sio.loadmat('fft_train_1.mat')\n",
    "Y_train = dataset['Y_train']\n",
    "Y_train = (Y_train - 50) / 150\n",
    "X_train = dataset['X_trainB'].transpose(0, 2, 1)\n",
    "print(Y_train.shape)\n",
    "print(X_train.shape)\n",
    "x_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(Y_train).float()\n",
    "torch_train = Data.TensorDataset(x_train, y_train)\n",
    "train_loader = Data.DataLoader(dataset=torch_train,\n",
    "                              batch_size=128,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x181601b358>,\n",
       " <matplotlib.lines.Line2D at 0x181601b1d0>,\n",
       " <matplotlib.lines.Line2D at 0x1815f9eb70>,\n",
       " <matplotlib.lines.Line2D at 0x1815f9eac8>,\n",
       " <matplotlib.lines.Line2D at 0x1815f9ed68>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181607be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(a[1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def normali(input):\n",
    "\t'''\n",
    "\tThis function aim to normalize X_train\n",
    "\t'''\n",
    "\tfor i in range(input.shape[2]):\n",
    "\t\ttem = input[:, :, i]\n",
    "\t\ttem = tem/(np.max(tem) - np.min(tem))\n",
    "\t\tinput[:, :, i] = tem\n",
    "\treturn input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = normali(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(a).float()\n",
    "y_train = torch.from_numpy(Y_train).float()\n",
    "torch_train = Data.TensorDataset(x_train, y_train)\n",
    "train_loader = Data.DataLoader(dataset=torch_train,\n",
    "                              batch_size=128,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 1)\n",
      "(148, 5, 110)\n"
     ]
    }
   ],
   "source": [
    "dataset = sio.loadmat('fft_test_1.mat')\n",
    "Y_test = dataset['Y_test']\n",
    "Y_test = (Y_test - 50) / 150\n",
    "X_test = dataset['X_testB']\n",
    "X_test = normali(X_test)\n",
    "X_test = X_test.transpose(0, 2, 1)\n",
    "print(Y_test.shape)\n",
    "print(X_test.shape)\n",
    "x_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(Y_test).float()\n",
    "torch_test = Data.TensorDataset(x_test, y_test)\n",
    "test_loader = Data.DataLoader(dataset=torch_test,\n",
    "                              batch_size=148,\n",
    "                              shuffle=True,\n",
    "                              num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        #data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         if batch_idx % 5 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                     epoch, batch_idx*len(data), len(train_loader.dataset),\n",
    "#                     100.*batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        #data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        criterion = nn.MSELoss()\n",
    "        test_loss = criterion(output, target)\n",
    "        \n",
    "    print('testing loss: ', test_loss)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xufanxiong/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:995: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss:  tensor(0.0674, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920],\n",
      "        [0.3920]], grad_fn=<TanhBackward>)\n",
      "testing loss:  tensor(0.0470, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.4769],\n",
      "        [0.4744],\n",
      "        [0.4731],\n",
      "        [0.4733],\n",
      "        [0.4693],\n",
      "        [0.4747],\n",
      "        [0.4737],\n",
      "        [0.4692],\n",
      "        [0.4757],\n",
      "        [0.4719],\n",
      "        [0.4762],\n",
      "        [0.4720],\n",
      "        [0.4717],\n",
      "        [0.4695],\n",
      "        [0.4756],\n",
      "        [0.4705],\n",
      "        [0.4748],\n",
      "        [0.4711],\n",
      "        [0.4703],\n",
      "        [0.4779],\n",
      "        [0.4692],\n",
      "        [0.4745],\n",
      "        [0.4712],\n",
      "        [0.4713],\n",
      "        [0.4710],\n",
      "        [0.4763],\n",
      "        [0.4744],\n",
      "        [0.4741],\n",
      "        [0.4694],\n",
      "        [0.4778],\n",
      "        [0.4743],\n",
      "        [0.4725],\n",
      "        [0.4693],\n",
      "        [0.4762],\n",
      "        [0.4790],\n",
      "        [0.4739],\n",
      "        [0.4720],\n",
      "        [0.4724],\n",
      "        [0.4727],\n",
      "        [0.4705],\n",
      "        [0.4718],\n",
      "        [0.4690],\n",
      "        [0.4758],\n",
      "        [0.4716],\n",
      "        [0.4737],\n",
      "        [0.4731],\n",
      "        [0.4693],\n",
      "        [0.4728],\n",
      "        [0.4713],\n",
      "        [0.4744],\n",
      "        [0.4683],\n",
      "        [0.4732],\n",
      "        [0.4696],\n",
      "        [0.4759],\n",
      "        [0.4729],\n",
      "        [0.4763],\n",
      "        [0.4761],\n",
      "        [0.4741],\n",
      "        [0.4715],\n",
      "        [0.4757],\n",
      "        [0.4724],\n",
      "        [0.4703],\n",
      "        [0.4775],\n",
      "        [0.4716],\n",
      "        [0.4718],\n",
      "        [0.4752],\n",
      "        [0.4736],\n",
      "        [0.4759],\n",
      "        [0.4734],\n",
      "        [0.4697],\n",
      "        [0.4716],\n",
      "        [0.4727],\n",
      "        [0.4727],\n",
      "        [0.4757],\n",
      "        [0.4736],\n",
      "        [0.4689],\n",
      "        [0.4751],\n",
      "        [0.4788],\n",
      "        [0.4759],\n",
      "        [0.4709],\n",
      "        [0.4750],\n",
      "        [0.4745],\n",
      "        [0.4695],\n",
      "        [0.4708],\n",
      "        [0.4697],\n",
      "        [0.4741],\n",
      "        [0.4692],\n",
      "        [0.4751],\n",
      "        [0.4744],\n",
      "        [0.4734],\n",
      "        [0.4728],\n",
      "        [0.4727],\n",
      "        [0.4728],\n",
      "        [0.4744],\n",
      "        [0.4768],\n",
      "        [0.4735],\n",
      "        [0.4692],\n",
      "        [0.4705],\n",
      "        [0.4741],\n",
      "        [0.4728],\n",
      "        [0.4783],\n",
      "        [0.4691],\n",
      "        [0.4727],\n",
      "        [0.4694],\n",
      "        [0.4706],\n",
      "        [0.4731],\n",
      "        [0.4700],\n",
      "        [0.4729],\n",
      "        [0.4699],\n",
      "        [0.4703],\n",
      "        [0.4740],\n",
      "        [0.4746],\n",
      "        [0.4726],\n",
      "        [0.4753],\n",
      "        [0.4742],\n",
      "        [0.4720],\n",
      "        [0.4719],\n",
      "        [0.4716],\n",
      "        [0.4719],\n",
      "        [0.4697],\n",
      "        [0.4723],\n",
      "        [0.4729],\n",
      "        [0.4699],\n",
      "        [0.4743],\n",
      "        [0.4735],\n",
      "        [0.4756],\n",
      "        [0.4716],\n",
      "        [0.4693],\n",
      "        [0.4724],\n",
      "        [0.4693],\n",
      "        [0.4723],\n",
      "        [0.4753],\n",
      "        [0.4725],\n",
      "        [0.4740],\n",
      "        [0.4725],\n",
      "        [0.4767],\n",
      "        [0.4736],\n",
      "        [0.4762],\n",
      "        [0.4740],\n",
      "        [0.4701],\n",
      "        [0.4737],\n",
      "        [0.4728],\n",
      "        [0.4771],\n",
      "        [0.4716],\n",
      "        [0.4725],\n",
      "        [0.4695],\n",
      "        [0.4744],\n",
      "        [0.4734]], grad_fn=<TanhBackward>)\n",
      "testing loss:  tensor(0.0369, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.5940],\n",
      "        [0.5857],\n",
      "        [0.6045],\n",
      "        [0.5483],\n",
      "        [0.5680],\n",
      "        [0.5884],\n",
      "        [0.5638],\n",
      "        [0.5561],\n",
      "        [0.5549],\n",
      "        [0.5994],\n",
      "        [0.6058],\n",
      "        [0.5916],\n",
      "        [0.5839],\n",
      "        [0.5850],\n",
      "        [0.5913],\n",
      "        [0.6311],\n",
      "        [0.5583],\n",
      "        [0.5727],\n",
      "        [0.6241],\n",
      "        [0.5791],\n",
      "        [0.6370],\n",
      "        [0.5992],\n",
      "        [0.5541],\n",
      "        [0.6067],\n",
      "        [0.5715],\n",
      "        [0.5555],\n",
      "        [0.6040],\n",
      "        [0.5517],\n",
      "        [0.5571],\n",
      "        [0.6146],\n",
      "        [0.5646],\n",
      "        [0.5497],\n",
      "        [0.5972],\n",
      "        [0.5872],\n",
      "        [0.6075],\n",
      "        [0.5893],\n",
      "        [0.5532],\n",
      "        [0.6095],\n",
      "        [0.6133],\n",
      "        [0.5761],\n",
      "        [0.5805],\n",
      "        [0.6094],\n",
      "        [0.5526],\n",
      "        [0.5552],\n",
      "        [0.5797],\n",
      "        [0.6203],\n",
      "        [0.6184],\n",
      "        [0.5641],\n",
      "        [0.5770],\n",
      "        [0.6241],\n",
      "        [0.6056],\n",
      "        [0.5875],\n",
      "        [0.5664],\n",
      "        [0.5800],\n",
      "        [0.5783],\n",
      "        [0.5826],\n",
      "        [0.5769],\n",
      "        [0.5790],\n",
      "        [0.6038],\n",
      "        [0.5899],\n",
      "        [0.6013],\n",
      "        [0.6030],\n",
      "        [0.5808],\n",
      "        [0.5936],\n",
      "        [0.5747],\n",
      "        [0.5571],\n",
      "        [0.5558],\n",
      "        [0.5783],\n",
      "        [0.5803],\n",
      "        [0.5674],\n",
      "        [0.5776],\n",
      "        [0.5920],\n",
      "        [0.6085],\n",
      "        [0.5721],\n",
      "        [0.5543],\n",
      "        [0.5924],\n",
      "        [0.5852],\n",
      "        [0.6083],\n",
      "        [0.5785],\n",
      "        [0.5904],\n",
      "        [0.5805],\n",
      "        [0.5711],\n",
      "        [0.6182],\n",
      "        [0.5739],\n",
      "        [0.5869],\n",
      "        [0.6061],\n",
      "        [0.6261],\n",
      "        [0.5606],\n",
      "        [0.6048],\n",
      "        [0.6276],\n",
      "        [0.5878],\n",
      "        [0.6031],\n",
      "        [0.5758],\n",
      "        [0.5540],\n",
      "        [0.6242],\n",
      "        [0.5655],\n",
      "        [0.6121],\n",
      "        [0.5566],\n",
      "        [0.5598],\n",
      "        [0.6139],\n",
      "        [0.5597],\n",
      "        [0.6106],\n",
      "        [0.5525],\n",
      "        [0.6003],\n",
      "        [0.5910],\n",
      "        [0.5723],\n",
      "        [0.5778],\n",
      "        [0.5838],\n",
      "        [0.5528],\n",
      "        [0.6263],\n",
      "        [0.5885],\n",
      "        [0.6137],\n",
      "        [0.5844],\n",
      "        [0.5561],\n",
      "        [0.6177],\n",
      "        [0.6113],\n",
      "        [0.5575],\n",
      "        [0.5516],\n",
      "        [0.6060],\n",
      "        [0.5864],\n",
      "        [0.5767],\n",
      "        [0.6242],\n",
      "        [0.5961],\n",
      "        [0.5764],\n",
      "        [0.5976],\n",
      "        [0.5838],\n",
      "        [0.5847],\n",
      "        [0.5620],\n",
      "        [0.5652],\n",
      "        [0.5766],\n",
      "        [0.6187],\n",
      "        [0.5845],\n",
      "        [0.5732],\n",
      "        [0.5868],\n",
      "        [0.6236],\n",
      "        [0.6318],\n",
      "        [0.5534],\n",
      "        [0.6103],\n",
      "        [0.6004],\n",
      "        [0.5778],\n",
      "        [0.5911],\n",
      "        [0.5908],\n",
      "        [0.6138],\n",
      "        [0.5668],\n",
      "        [0.5965],\n",
      "        [0.5521],\n",
      "        [0.5811],\n",
      "        [0.5747]], grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss:  tensor(0.0366, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.5733],\n",
      "        [0.5756],\n",
      "        [0.5569],\n",
      "        [0.5623],\n",
      "        [0.5184],\n",
      "        [0.5631],\n",
      "        [0.5701],\n",
      "        [0.5183],\n",
      "        [0.5603],\n",
      "        [0.5802],\n",
      "        [0.5653],\n",
      "        [0.5613],\n",
      "        [0.5199],\n",
      "        [0.5718],\n",
      "        [0.5728],\n",
      "        [0.5080],\n",
      "        [0.5602],\n",
      "        [0.5738],\n",
      "        [0.5203],\n",
      "        [0.5404],\n",
      "        [0.5739],\n",
      "        [0.5168],\n",
      "        [0.5586],\n",
      "        [0.5547],\n",
      "        [0.5642],\n",
      "        [0.5717],\n",
      "        [0.5970],\n",
      "        [0.5481],\n",
      "        [0.5660],\n",
      "        [0.5494],\n",
      "        [0.5662],\n",
      "        [0.5676],\n",
      "        [0.5660],\n",
      "        [0.5644],\n",
      "        [0.5412],\n",
      "        [0.5867],\n",
      "        [0.6033],\n",
      "        [0.5554],\n",
      "        [0.5823],\n",
      "        [0.5590],\n",
      "        [0.5610],\n",
      "        [0.5951],\n",
      "        [0.6000],\n",
      "        [0.5558],\n",
      "        [0.6025],\n",
      "        [0.5443],\n",
      "        [0.5929],\n",
      "        [0.5526],\n",
      "        [0.5797],\n",
      "        [0.6076],\n",
      "        [0.6085],\n",
      "        [0.5506],\n",
      "        [0.5824],\n",
      "        [0.5124],\n",
      "        [0.6129],\n",
      "        [0.5410],\n",
      "        [0.5336],\n",
      "        [0.5502],\n",
      "        [0.6006],\n",
      "        [0.5414],\n",
      "        [0.5206],\n",
      "        [0.5470],\n",
      "        [0.5791],\n",
      "        [0.5340],\n",
      "        [0.5475],\n",
      "        [0.5569],\n",
      "        [0.5239],\n",
      "        [0.5201],\n",
      "        [0.5633],\n",
      "        [0.5214],\n",
      "        [0.5315],\n",
      "        [0.6009],\n",
      "        [0.5186],\n",
      "        [0.5189],\n",
      "        [0.5934],\n",
      "        [0.5841],\n",
      "        [0.5987],\n",
      "        [0.5550],\n",
      "        [0.5107],\n",
      "        [0.5959],\n",
      "        [0.5932],\n",
      "        [0.5750],\n",
      "        [0.5363],\n",
      "        [0.5229],\n",
      "        [0.5762],\n",
      "        [0.6048],\n",
      "        [0.5532],\n",
      "        [0.5896],\n",
      "        [0.5124],\n",
      "        [0.6020],\n",
      "        [0.5800],\n",
      "        [0.5457],\n",
      "        [0.5901],\n",
      "        [0.5219],\n",
      "        [0.5049],\n",
      "        [0.5115],\n",
      "        [0.5837],\n",
      "        [0.5506],\n",
      "        [0.5265],\n",
      "        [0.6005],\n",
      "        [0.5639],\n",
      "        [0.5590],\n",
      "        [0.5191],\n",
      "        [0.5697],\n",
      "        [0.5983],\n",
      "        [0.5933],\n",
      "        [0.5678],\n",
      "        [0.5443],\n",
      "        [0.6061],\n",
      "        [0.5197],\n",
      "        [0.5583],\n",
      "        [0.5754],\n",
      "        [0.5168],\n",
      "        [0.5834],\n",
      "        [0.5129],\n",
      "        [0.5606],\n",
      "        [0.5518],\n",
      "        [0.5818],\n",
      "        [0.5800],\n",
      "        [0.5825],\n",
      "        [0.5659],\n",
      "        [0.5577],\n",
      "        [0.5170],\n",
      "        [0.5534],\n",
      "        [0.5683],\n",
      "        [0.5089],\n",
      "        [0.5208],\n",
      "        [0.5584],\n",
      "        [0.6167],\n",
      "        [0.5577],\n",
      "        [0.5209],\n",
      "        [0.5904],\n",
      "        [0.5832],\n",
      "        [0.5253],\n",
      "        [0.5506],\n",
      "        [0.5656],\n",
      "        [0.5175],\n",
      "        [0.5939],\n",
      "        [0.5686],\n",
      "        [0.5671],\n",
      "        [0.5615],\n",
      "        [0.6079],\n",
      "        [0.5609],\n",
      "        [0.5631],\n",
      "        [0.5815],\n",
      "        [0.5826],\n",
      "        [0.5263],\n",
      "        [0.5647]], grad_fn=<TanhBackward>)\n",
      "testing loss:  tensor(0.0370, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.6230],\n",
      "        [0.6093],\n",
      "        [0.5906],\n",
      "        [0.5874],\n",
      "        [0.5592],\n",
      "        [0.5994],\n",
      "        [0.6095],\n",
      "        [0.6352],\n",
      "        [0.5584],\n",
      "        [0.5887],\n",
      "        [0.6226],\n",
      "        [0.6337],\n",
      "        [0.6154],\n",
      "        [0.6146],\n",
      "        [0.5665],\n",
      "        [0.5837],\n",
      "        [0.5746],\n",
      "        [0.6077],\n",
      "        [0.5727],\n",
      "        [0.5693],\n",
      "        [0.5895],\n",
      "        [0.6136],\n",
      "        [0.5640],\n",
      "        [0.5912],\n",
      "        [0.5602],\n",
      "        [0.5808],\n",
      "        [0.5904],\n",
      "        [0.6180],\n",
      "        [0.5741],\n",
      "        [0.5628],\n",
      "        [0.5702],\n",
      "        [0.5960],\n",
      "        [0.6135],\n",
      "        [0.5802],\n",
      "        [0.5842],\n",
      "        [0.6291],\n",
      "        [0.6161],\n",
      "        [0.5620],\n",
      "        [0.5920],\n",
      "        [0.5612],\n",
      "        [0.5556],\n",
      "        [0.5889],\n",
      "        [0.5987],\n",
      "        [0.5847],\n",
      "        [0.5908],\n",
      "        [0.5611],\n",
      "        [0.6365],\n",
      "        [0.5848],\n",
      "        [0.6313],\n",
      "        [0.5885],\n",
      "        [0.5735],\n",
      "        [0.6243],\n",
      "        [0.5587],\n",
      "        [0.5515],\n",
      "        [0.5593],\n",
      "        [0.6282],\n",
      "        [0.5861],\n",
      "        [0.6254],\n",
      "        [0.5524],\n",
      "        [0.5947],\n",
      "        [0.6209],\n",
      "        [0.6012],\n",
      "        [0.5857],\n",
      "        [0.5818],\n",
      "        [0.5937],\n",
      "        [0.5739],\n",
      "        [0.6126],\n",
      "        [0.6136],\n",
      "        [0.5620],\n",
      "        [0.5634],\n",
      "        [0.6000],\n",
      "        [0.5932],\n",
      "        [0.5734],\n",
      "        [0.6405],\n",
      "        [0.6247],\n",
      "        [0.5718],\n",
      "        [0.5808],\n",
      "        [0.5770],\n",
      "        [0.5498],\n",
      "        [0.6248],\n",
      "        [0.6334],\n",
      "        [0.5920],\n",
      "        [0.6217],\n",
      "        [0.5500],\n",
      "        [0.6044],\n",
      "        [0.5584],\n",
      "        [0.5665],\n",
      "        [0.6346],\n",
      "        [0.6024],\n",
      "        [0.5840],\n",
      "        [0.5947],\n",
      "        [0.5570],\n",
      "        [0.5915],\n",
      "        [0.5754],\n",
      "        [0.5663],\n",
      "        [0.6182],\n",
      "        [0.5938],\n",
      "        [0.5974],\n",
      "        [0.6366],\n",
      "        [0.5664],\n",
      "        [0.6129],\n",
      "        [0.6175],\n",
      "        [0.6136],\n",
      "        [0.6062],\n",
      "        [0.6091],\n",
      "        [0.6179],\n",
      "        [0.5921],\n",
      "        [0.6134],\n",
      "        [0.6218],\n",
      "        [0.5839],\n",
      "        [0.5743],\n",
      "        [0.5603],\n",
      "        [0.5704],\n",
      "        [0.5773],\n",
      "        [0.6224],\n",
      "        [0.5968],\n",
      "        [0.6092],\n",
      "        [0.5628],\n",
      "        [0.5889],\n",
      "        [0.5838],\n",
      "        [0.6276],\n",
      "        [0.5921],\n",
      "        [0.5670],\n",
      "        [0.5984],\n",
      "        [0.6114],\n",
      "        [0.6146],\n",
      "        [0.6042],\n",
      "        [0.5844],\n",
      "        [0.5616],\n",
      "        [0.5611],\n",
      "        [0.5586],\n",
      "        [0.6159],\n",
      "        [0.6388],\n",
      "        [0.5910],\n",
      "        [0.5998],\n",
      "        [0.6340],\n",
      "        [0.6304],\n",
      "        [0.5680],\n",
      "        [0.5808],\n",
      "        [0.5946],\n",
      "        [0.6017],\n",
      "        [0.6249],\n",
      "        [0.5572],\n",
      "        [0.5885],\n",
      "        [0.5936],\n",
      "        [0.5642],\n",
      "        [0.5850],\n",
      "        [0.6026]], grad_fn=<TanhBackward>)\n",
      "testing loss:  tensor(0.0376, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.6013],\n",
      "        [0.5968],\n",
      "        [0.5909],\n",
      "        [0.5536],\n",
      "        [0.6291],\n",
      "        [0.5848],\n",
      "        [0.6140],\n",
      "        [0.6220],\n",
      "        [0.6260],\n",
      "        [0.5553],\n",
      "        [0.6002],\n",
      "        [0.5594],\n",
      "        [0.6120],\n",
      "        [0.5544],\n",
      "        [0.5520],\n",
      "        [0.5550],\n",
      "        [0.5543],\n",
      "        [0.5591],\n",
      "        [0.5381],\n",
      "        [0.5972],\n",
      "        [0.6192],\n",
      "        [0.5841],\n",
      "        [0.6234],\n",
      "        [0.6299],\n",
      "        [0.6428],\n",
      "        [0.5683],\n",
      "        [0.5936],\n",
      "        [0.5521],\n",
      "        [0.6101],\n",
      "        [0.5484],\n",
      "        [0.5553],\n",
      "        [0.5830],\n",
      "        [0.5423],\n",
      "        [0.5743],\n",
      "        [0.6250],\n",
      "        [0.5937],\n",
      "        [0.5894],\n",
      "        [0.5947],\n",
      "        [0.5702],\n",
      "        [0.6240],\n",
      "        [0.5889],\n",
      "        [0.5826],\n",
      "        [0.6410],\n",
      "        [0.6016],\n",
      "        [0.5966],\n",
      "        [0.5954],\n",
      "        [0.6075],\n",
      "        [0.5965],\n",
      "        [0.5837],\n",
      "        [0.5556],\n",
      "        [0.6267],\n",
      "        [0.6305],\n",
      "        [0.5596],\n",
      "        [0.5885],\n",
      "        [0.6110],\n",
      "        [0.5853],\n",
      "        [0.5584],\n",
      "        [0.6148],\n",
      "        [0.6284],\n",
      "        [0.5766],\n",
      "        [0.5877],\n",
      "        [0.5871],\n",
      "        [0.5827],\n",
      "        [0.5871],\n",
      "        [0.5614],\n",
      "        [0.5960],\n",
      "        [0.6097],\n",
      "        [0.5833],\n",
      "        [0.5815],\n",
      "        [0.5611],\n",
      "        [0.6321],\n",
      "        [0.6249],\n",
      "        [0.5755],\n",
      "        [0.6123],\n",
      "        [0.5877],\n",
      "        [0.6255],\n",
      "        [0.5616],\n",
      "        [0.5616],\n",
      "        [0.5796],\n",
      "        [0.5662],\n",
      "        [0.6195],\n",
      "        [0.5971],\n",
      "        [0.5831],\n",
      "        [0.5770],\n",
      "        [0.5782],\n",
      "        [0.5787],\n",
      "        [0.6265],\n",
      "        [0.5936],\n",
      "        [0.6097],\n",
      "        [0.5564],\n",
      "        [0.6254],\n",
      "        [0.5750],\n",
      "        [0.5906],\n",
      "        [0.5589],\n",
      "        [0.5804],\n",
      "        [0.5510],\n",
      "        [0.5403],\n",
      "        [0.6221],\n",
      "        [0.5871],\n",
      "        [0.5774],\n",
      "        [0.5593],\n",
      "        [0.6153],\n",
      "        [0.5844],\n",
      "        [0.5818],\n",
      "        [0.5941],\n",
      "        [0.5463],\n",
      "        [0.5931],\n",
      "        [0.5590],\n",
      "        [0.5955],\n",
      "        [0.6351],\n",
      "        [0.5652],\n",
      "        [0.5985],\n",
      "        [0.5445],\n",
      "        [0.6141],\n",
      "        [0.5943],\n",
      "        [0.5556],\n",
      "        [0.6134],\n",
      "        [0.6064],\n",
      "        [0.5385],\n",
      "        [0.6166],\n",
      "        [0.5763],\n",
      "        [0.5610],\n",
      "        [0.5828],\n",
      "        [0.6058],\n",
      "        [0.6273],\n",
      "        [0.5744],\n",
      "        [0.6072],\n",
      "        [0.5583],\n",
      "        [0.5505],\n",
      "        [0.6076],\n",
      "        [0.6102],\n",
      "        [0.5787],\n",
      "        [0.5713],\n",
      "        [0.5846],\n",
      "        [0.6126],\n",
      "        [0.5615],\n",
      "        [0.6033],\n",
      "        [0.5368],\n",
      "        [0.5518],\n",
      "        [0.6032],\n",
      "        [0.5686],\n",
      "        [0.6026],\n",
      "        [0.5542],\n",
      "        [0.5575],\n",
      "        [0.6367],\n",
      "        [0.6132],\n",
      "        [0.5505],\n",
      "        [0.5837]], grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss:  tensor(0.0359, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.6201],\n",
      "        [0.6030],\n",
      "        [0.5876],\n",
      "        [0.5562],\n",
      "        [0.5998],\n",
      "        [0.6230],\n",
      "        [0.5970],\n",
      "        [0.6086],\n",
      "        [0.5741],\n",
      "        [0.6005],\n",
      "        [0.5722],\n",
      "        [0.5402],\n",
      "        [0.5939],\n",
      "        [0.6331],\n",
      "        [0.6282],\n",
      "        [0.5758],\n",
      "        [0.5540],\n",
      "        [0.5467],\n",
      "        [0.5725],\n",
      "        [0.5449],\n",
      "        [0.6011],\n",
      "        [0.6322],\n",
      "        [0.5818],\n",
      "        [0.6061],\n",
      "        [0.5409],\n",
      "        [0.5627],\n",
      "        [0.5867],\n",
      "        [0.6267],\n",
      "        [0.5438],\n",
      "        [0.6359],\n",
      "        [0.5326],\n",
      "        [0.5525],\n",
      "        [0.5824],\n",
      "        [0.5898],\n",
      "        [0.5933],\n",
      "        [0.6380],\n",
      "        [0.5515],\n",
      "        [0.6205],\n",
      "        [0.6332],\n",
      "        [0.5826],\n",
      "        [0.5879],\n",
      "        [0.5961],\n",
      "        [0.5822],\n",
      "        [0.5439],\n",
      "        [0.5665],\n",
      "        [0.5558],\n",
      "        [0.5783],\n",
      "        [0.6339],\n",
      "        [0.6153],\n",
      "        [0.5874],\n",
      "        [0.6196],\n",
      "        [0.5378],\n",
      "        [0.5507],\n",
      "        [0.6097],\n",
      "        [0.5640],\n",
      "        [0.5600],\n",
      "        [0.6167],\n",
      "        [0.6275],\n",
      "        [0.5961],\n",
      "        [0.6174],\n",
      "        [0.5435],\n",
      "        [0.5837],\n",
      "        [0.5733],\n",
      "        [0.5759],\n",
      "        [0.5352],\n",
      "        [0.6007],\n",
      "        [0.5896],\n",
      "        [0.5788],\n",
      "        [0.5757],\n",
      "        [0.5423],\n",
      "        [0.6322],\n",
      "        [0.6386],\n",
      "        [0.5818],\n",
      "        [0.6132],\n",
      "        [0.5201],\n",
      "        [0.5612],\n",
      "        [0.5972],\n",
      "        [0.5538],\n",
      "        [0.5962],\n",
      "        [0.5804],\n",
      "        [0.5360],\n",
      "        [0.5948],\n",
      "        [0.5832],\n",
      "        [0.5461],\n",
      "        [0.6246],\n",
      "        [0.5362],\n",
      "        [0.5936],\n",
      "        [0.5710],\n",
      "        [0.5338],\n",
      "        [0.5430],\n",
      "        [0.5416],\n",
      "        [0.5714],\n",
      "        [0.6117],\n",
      "        [0.5897],\n",
      "        [0.6270],\n",
      "        [0.5847],\n",
      "        [0.6077],\n",
      "        [0.6093],\n",
      "        [0.5406],\n",
      "        [0.6055],\n",
      "        [0.6136],\n",
      "        [0.6211],\n",
      "        [0.6232],\n",
      "        [0.6016],\n",
      "        [0.5852],\n",
      "        [0.5896],\n",
      "        [0.6101],\n",
      "        [0.5918],\n",
      "        [0.5710],\n",
      "        [0.6173],\n",
      "        [0.6275],\n",
      "        [0.6195],\n",
      "        [0.6249],\n",
      "        [0.5440],\n",
      "        [0.5581],\n",
      "        [0.5410],\n",
      "        [0.5466],\n",
      "        [0.5994],\n",
      "        [0.5641],\n",
      "        [0.5822],\n",
      "        [0.6069],\n",
      "        [0.5450],\n",
      "        [0.6045],\n",
      "        [0.5781],\n",
      "        [0.5975],\n",
      "        [0.6234],\n",
      "        [0.6017],\n",
      "        [0.5845],\n",
      "        [0.5879],\n",
      "        [0.6143],\n",
      "        [0.6018],\n",
      "        [0.5679],\n",
      "        [0.5494],\n",
      "        [0.5985],\n",
      "        [0.6203],\n",
      "        [0.5962],\n",
      "        [0.5323],\n",
      "        [0.5690],\n",
      "        [0.6110],\n",
      "        [0.6183],\n",
      "        [0.5816],\n",
      "        [0.6119],\n",
      "        [0.5778],\n",
      "        [0.5643],\n",
      "        [0.5283],\n",
      "        [0.5869],\n",
      "        [0.6263],\n",
      "        [0.5946]], grad_fn=<TanhBackward>)\n",
      "testing loss:  tensor(0.0351, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.5788],\n",
      "        [0.5403],\n",
      "        [0.5371],\n",
      "        [0.5322],\n",
      "        [0.5160],\n",
      "        [0.5546],\n",
      "        [0.5417],\n",
      "        [0.6216],\n",
      "        [0.5716],\n",
      "        [0.5792],\n",
      "        [0.5847],\n",
      "        [0.5401],\n",
      "        [0.5282],\n",
      "        [0.5394],\n",
      "        [0.5290],\n",
      "        [0.5785],\n",
      "        [0.5397],\n",
      "        [0.5592],\n",
      "        [0.5963],\n",
      "        [0.5350],\n",
      "        [0.5250],\n",
      "        [0.5381],\n",
      "        [0.5692],\n",
      "        [0.5289],\n",
      "        [0.5878],\n",
      "        [0.5306],\n",
      "        [0.5763],\n",
      "        [0.5501],\n",
      "        [0.5594],\n",
      "        [0.5290],\n",
      "        [0.5249],\n",
      "        [0.5350],\n",
      "        [0.6136],\n",
      "        [0.6189],\n",
      "        [0.5396],\n",
      "        [0.5435],\n",
      "        [0.5403],\n",
      "        [0.4945],\n",
      "        [0.5220],\n",
      "        [0.5128],\n",
      "        [0.5574],\n",
      "        [0.5654],\n",
      "        [0.5202],\n",
      "        [0.5985],\n",
      "        [0.5385],\n",
      "        [0.5360],\n",
      "        [0.5537],\n",
      "        [0.5398],\n",
      "        [0.5899],\n",
      "        [0.5709],\n",
      "        [0.5745],\n",
      "        [0.5535],\n",
      "        [0.6218],\n",
      "        [0.5872],\n",
      "        [0.5890],\n",
      "        [0.5381],\n",
      "        [0.5546],\n",
      "        [0.5627],\n",
      "        [0.5510],\n",
      "        [0.5194],\n",
      "        [0.5467],\n",
      "        [0.5436],\n",
      "        [0.5485],\n",
      "        [0.5701],\n",
      "        [0.5999],\n",
      "        [0.5618],\n",
      "        [0.5928],\n",
      "        [0.5887],\n",
      "        [0.5781],\n",
      "        [0.5484],\n",
      "        [0.5448],\n",
      "        [0.5259],\n",
      "        [0.5321],\n",
      "        [0.5890],\n",
      "        [0.5980],\n",
      "        [0.5313],\n",
      "        [0.5641],\n",
      "        [0.5280],\n",
      "        [0.5261],\n",
      "        [0.5434],\n",
      "        [0.5678],\n",
      "        [0.5155],\n",
      "        [0.5615],\n",
      "        [0.5548],\n",
      "        [0.5973],\n",
      "        [0.5530],\n",
      "        [0.5332],\n",
      "        [0.5428],\n",
      "        [0.5850],\n",
      "        [0.5793],\n",
      "        [0.5606],\n",
      "        [0.5290],\n",
      "        [0.5992],\n",
      "        [0.5340],\n",
      "        [0.5698],\n",
      "        [0.5252],\n",
      "        [0.5702],\n",
      "        [0.6008],\n",
      "        [0.5022],\n",
      "        [0.5446],\n",
      "        [0.5299],\n",
      "        [0.5287],\n",
      "        [0.5219],\n",
      "        [0.5804],\n",
      "        [0.5567],\n",
      "        [0.5206],\n",
      "        [0.5390],\n",
      "        [0.5530],\n",
      "        [0.5569],\n",
      "        [0.5931],\n",
      "        [0.5820],\n",
      "        [0.5779],\n",
      "        [0.5640],\n",
      "        [0.5497],\n",
      "        [0.5959],\n",
      "        [0.5936],\n",
      "        [0.5738],\n",
      "        [0.5080],\n",
      "        [0.5887],\n",
      "        [0.5490],\n",
      "        [0.5454],\n",
      "        [0.5386],\n",
      "        [0.5123],\n",
      "        [0.6184],\n",
      "        [0.5282],\n",
      "        [0.5650],\n",
      "        [0.5240],\n",
      "        [0.5268],\n",
      "        [0.5610],\n",
      "        [0.5617],\n",
      "        [0.5640],\n",
      "        [0.5368],\n",
      "        [0.5415],\n",
      "        [0.5182],\n",
      "        [0.5489],\n",
      "        [0.5590],\n",
      "        [0.5544],\n",
      "        [0.5564],\n",
      "        [0.5299],\n",
      "        [0.6066],\n",
      "        [0.6129],\n",
      "        [0.6162],\n",
      "        [0.5536],\n",
      "        [0.5850],\n",
      "        [0.6107],\n",
      "        [0.6059],\n",
      "        [0.5139],\n",
      "        [0.5830]], grad_fn=<TanhBackward>)\n",
      "testing loss:  tensor(0.0404, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.5113],\n",
      "        [0.4921],\n",
      "        [0.4749],\n",
      "        [0.4947],\n",
      "        [0.5026],\n",
      "        [0.4735],\n",
      "        [0.5718],\n",
      "        [0.5388],\n",
      "        [0.5111],\n",
      "        [0.4311],\n",
      "        [0.4841],\n",
      "        [0.4860],\n",
      "        [0.5405],\n",
      "        [0.5071],\n",
      "        [0.4829],\n",
      "        [0.5026],\n",
      "        [0.4771],\n",
      "        [0.5205],\n",
      "        [0.5557],\n",
      "        [0.5000],\n",
      "        [0.5562],\n",
      "        [0.4854],\n",
      "        [0.5006],\n",
      "        [0.4836],\n",
      "        [0.4779],\n",
      "        [0.5687],\n",
      "        [0.4980],\n",
      "        [0.4806],\n",
      "        [0.4936],\n",
      "        [0.4910],\n",
      "        [0.5481],\n",
      "        [0.5180],\n",
      "        [0.4675],\n",
      "        [0.5523],\n",
      "        [0.4706],\n",
      "        [0.4859],\n",
      "        [0.5364],\n",
      "        [0.4787],\n",
      "        [0.4633],\n",
      "        [0.5154],\n",
      "        [0.5456],\n",
      "        [0.4859],\n",
      "        [0.4875],\n",
      "        [0.5648],\n",
      "        [0.5197],\n",
      "        [0.4782],\n",
      "        [0.4879],\n",
      "        [0.4156],\n",
      "        [0.4524],\n",
      "        [0.5096],\n",
      "        [0.4738],\n",
      "        [0.5012],\n",
      "        [0.4577],\n",
      "        [0.5580],\n",
      "        [0.4869],\n",
      "        [0.5344],\n",
      "        [0.4951],\n",
      "        [0.5304],\n",
      "        [0.5171],\n",
      "        [0.4978],\n",
      "        [0.5476],\n",
      "        [0.4694],\n",
      "        [0.4843],\n",
      "        [0.5178],\n",
      "        [0.5149],\n",
      "        [0.4585],\n",
      "        [0.5508],\n",
      "        [0.5242],\n",
      "        [0.5086],\n",
      "        [0.4483],\n",
      "        [0.4733],\n",
      "        [0.5358],\n",
      "        [0.4402],\n",
      "        [0.4903],\n",
      "        [0.4644],\n",
      "        [0.4790],\n",
      "        [0.4672],\n",
      "        [0.4356],\n",
      "        [0.4921],\n",
      "        [0.4770],\n",
      "        [0.4677],\n",
      "        [0.4888],\n",
      "        [0.4821],\n",
      "        [0.5652],\n",
      "        [0.4466],\n",
      "        [0.4838],\n",
      "        [0.4808],\n",
      "        [0.5249],\n",
      "        [0.5266],\n",
      "        [0.5374],\n",
      "        [0.5109],\n",
      "        [0.4901],\n",
      "        [0.4952],\n",
      "        [0.4507],\n",
      "        [0.4596],\n",
      "        [0.4650],\n",
      "        [0.4797],\n",
      "        [0.5513],\n",
      "        [0.5389],\n",
      "        [0.5056],\n",
      "        [0.5166],\n",
      "        [0.4790],\n",
      "        [0.4745],\n",
      "        [0.4809],\n",
      "        [0.5151],\n",
      "        [0.5158],\n",
      "        [0.5038],\n",
      "        [0.4758],\n",
      "        [0.5051],\n",
      "        [0.4841],\n",
      "        [0.5024],\n",
      "        [0.5081],\n",
      "        [0.5100],\n",
      "        [0.4801],\n",
      "        [0.4739],\n",
      "        [0.4562],\n",
      "        [0.5009],\n",
      "        [0.4908],\n",
      "        [0.5139],\n",
      "        [0.5008],\n",
      "        [0.5129],\n",
      "        [0.4842],\n",
      "        [0.5252],\n",
      "        [0.4676],\n",
      "        [0.5273],\n",
      "        [0.5214],\n",
      "        [0.4679],\n",
      "        [0.5633],\n",
      "        [0.4781],\n",
      "        [0.5381],\n",
      "        [0.4620],\n",
      "        [0.5530],\n",
      "        [0.5219],\n",
      "        [0.4888],\n",
      "        [0.5083],\n",
      "        [0.5357],\n",
      "        [0.4947],\n",
      "        [0.4833],\n",
      "        [0.5208],\n",
      "        [0.4928],\n",
      "        [0.4594],\n",
      "        [0.4805],\n",
      "        [0.4918],\n",
      "        [0.5575],\n",
      "        [0.4970],\n",
      "        [0.5610],\n",
      "        [0.4657],\n",
      "        [0.4875]], grad_fn=<TanhBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing loss:  tensor(0.0402, grad_fn=<MseLossBackward>)\n",
      "tensor([[0.5069],\n",
      "        [0.5608],\n",
      "        [0.5183],\n",
      "        [0.5100],\n",
      "        [0.5474],\n",
      "        [0.5452],\n",
      "        [0.5020],\n",
      "        [0.5204],\n",
      "        [0.5206],\n",
      "        [0.5561],\n",
      "        [0.5061],\n",
      "        [0.5038],\n",
      "        [0.4897],\n",
      "        [0.5231],\n",
      "        [0.5036],\n",
      "        [0.4886],\n",
      "        [0.4718],\n",
      "        [0.4626],\n",
      "        [0.4956],\n",
      "        [0.4915],\n",
      "        [0.5763],\n",
      "        [0.5097],\n",
      "        [0.4923],\n",
      "        [0.4847],\n",
      "        [0.4520],\n",
      "        [0.5793],\n",
      "        [0.4942],\n",
      "        [0.5207],\n",
      "        [0.5610],\n",
      "        [0.5256],\n",
      "        [0.5385],\n",
      "        [0.5274],\n",
      "        [0.5524],\n",
      "        [0.4992],\n",
      "        [0.5183],\n",
      "        [0.5149],\n",
      "        [0.4880],\n",
      "        [0.5718],\n",
      "        [0.5111],\n",
      "        [0.4827],\n",
      "        [0.5329],\n",
      "        [0.5305],\n",
      "        [0.5415],\n",
      "        [0.4821],\n",
      "        [0.5120],\n",
      "        [0.4692],\n",
      "        [0.4875],\n",
      "        [0.4991],\n",
      "        [0.5218],\n",
      "        [0.5284],\n",
      "        [0.5766],\n",
      "        [0.4822],\n",
      "        [0.5273],\n",
      "        [0.4917],\n",
      "        [0.5171],\n",
      "        [0.5181],\n",
      "        [0.5151],\n",
      "        [0.5589],\n",
      "        [0.5190],\n",
      "        [0.5346],\n",
      "        [0.5444],\n",
      "        [0.5678],\n",
      "        [0.5130],\n",
      "        [0.4642],\n",
      "        [0.5324],\n",
      "        [0.5013],\n",
      "        [0.5078],\n",
      "        [0.5173],\n",
      "        [0.5218],\n",
      "        [0.4913],\n",
      "        [0.4991],\n",
      "        [0.4925],\n",
      "        [0.5229],\n",
      "        [0.4914],\n",
      "        [0.4810],\n",
      "        [0.5168],\n",
      "        [0.5026],\n",
      "        [0.4967],\n",
      "        [0.5208],\n",
      "        [0.4918],\n",
      "        [0.5416],\n",
      "        [0.5223],\n",
      "        [0.4865],\n",
      "        [0.4897],\n",
      "        [0.5058],\n",
      "        [0.4916],\n",
      "        [0.4929],\n",
      "        [0.5147],\n",
      "        [0.5006],\n",
      "        [0.5115],\n",
      "        [0.4947],\n",
      "        [0.5085],\n",
      "        [0.5140],\n",
      "        [0.5273],\n",
      "        [0.5204],\n",
      "        [0.4806],\n",
      "        [0.4700],\n",
      "        [0.5069],\n",
      "        [0.4941],\n",
      "        [0.5609],\n",
      "        [0.5741],\n",
      "        [0.5132],\n",
      "        [0.5005],\n",
      "        [0.4833],\n",
      "        [0.4942],\n",
      "        [0.4983],\n",
      "        [0.5058],\n",
      "        [0.5316],\n",
      "        [0.5125],\n",
      "        [0.5353],\n",
      "        [0.5009],\n",
      "        [0.5174],\n",
      "        [0.4885],\n",
      "        [0.5208],\n",
      "        [0.4962],\n",
      "        [0.5139],\n",
      "        [0.5339],\n",
      "        [0.5188],\n",
      "        [0.4711],\n",
      "        [0.5607],\n",
      "        [0.4980],\n",
      "        [0.4841],\n",
      "        [0.5621],\n",
      "        [0.5029],\n",
      "        [0.4853],\n",
      "        [0.4758],\n",
      "        [0.5065],\n",
      "        [0.5163],\n",
      "        [0.5060],\n",
      "        [0.5120],\n",
      "        [0.5245],\n",
      "        [0.4926],\n",
      "        [0.5108],\n",
      "        [0.5244],\n",
      "        [0.4885],\n",
      "        [0.4428],\n",
      "        [0.4802],\n",
      "        [0.4934],\n",
      "        [0.4771],\n",
      "        [0.5338],\n",
      "        [0.5746],\n",
      "        [0.5084],\n",
      "        [0.5515],\n",
      "        [0.5556],\n",
      "        [0.5696],\n",
      "        [0.5194],\n",
      "        [0.4917],\n",
      "        [0.5134]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test11()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
